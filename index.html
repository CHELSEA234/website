<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Xiao Guo</title>

    <meta name="author" content="Xiao Guo">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

    <style>
      .papertitle { font-size: 18px; }

      /* ---------------- Exact mapping from your sizeMap ----------------
         Desktop: set width to pc; fix height=150 where specified.
         Mobile: set width to mobile; do NOT fix height on any image.  */

      /* Desktop (pc) */
      /* ---------- Desktop (pc) ---------- */
      @media (min-width: 769px) {
        /* pc: 280, height: 150 */
        #m2f2_img,
        #mmdet_img,
        #ddvqa_img,
        #denseface_img,
        #hifinet_img,
        #hifinet_img_v2,
        #mdfas_image,
        #RE_image,
        #lpgn_img,
        #motion_prediction_image {
          width: 280px !important;
          height: 150px !important;
          outline: 3px solid #bfbfbf;   /* gray bounding box */
          outline-offset: 0;             /* keep it tight */
          background: #f7f7f7;           /* optional light gray fill */
          display: inline-block;         /* for consistent box rendering */
        }

      }

      /* ---------- Mobile ---------- */
      @media (max-width: 800px) {
        /* mobile: 160, height auto */
        #m2f2_img,
        #lpgn_img,
        #mmdet_img,
        #hifinet_img,
        #hifinet_img_v2,
        #ddvqa_img,
        #denseface_img,
        #mdfas_image,
        #RE_image,
        #motion_prediction_image {
          width: 150px !important;
          height: 86px !important;
          outline: 1px solid #bfbfbf;   /* gray bounding box */
          outline-offset: 0;             /* keep it tight */
          background: #f7f7f7;           /* optional light gray fill */
          display: inline-block;         /* for consistent box rendering */
        }
      }

      img { image-rendering: auto; }

      @media (max-width: 768px) {
          .papertitle {
            font-size: 14px !important; 
            line-height: 1.25;
            word-wrap: break-word;
            hyphens: auto;
          }
        }

    </style>
  </head>

  <body>
    <table style="width:100%;max-width:900px;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;"><tbody>
      <tr><td style="padding:0">
        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
          <tbody>
            <tr>
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Xiao Guo (郭晓)
                </p>
                <p>
                  I am a final-year Ph.D. student in the <a href="https://cvlab.cse.msu.edu/">CVLab</a> of Michigan State University, advised by Prof. <a href="https://scholar.google.com/citations?hl=en&user=Bii0w1oAAAAJ">Xiaoming Liu</a>.
                  Before that, I spent years as a research programmer at <a href="https://www.isi.edu/">USC/ISI</a>, advised by Prof. <a href="https://iacopomasi.github.io/">Iacopo Masi</a> and Prof. <a href="https://viterbi.usc.edu/directory/faculty/Abd-Almageed/Wael">Wael AbdAlmageed</a>. I obtain my master and bachelor at the University of Southern California and Wuhan University of Technology, respectively.
                </p>
                <p>
                  I have been a main contributor to several major U.S. government-sponsored projects, including <a href="https://www.darpa.mil/research/programs/media-forensics">MediFor</a>, <a href="https://www.iarpa.gov/research-programs/odin">ODIN</a>, and <a href="https://www.darpa.mil/research/programs/reverse-engineering-of-deceptions">RED</a>.
                  In addition, I spent two wonderful summer as an intern at Amazon in 2023 and 2024, working with Dr. <a href="https://scholar.google.com/citations?user=fONV3IgAAAAJ&hl=en">Yue Rex Wu</a> and Dr. <a href="https://scholar.google.com/citations?user=RKp9_nQAAAAJ&hl=en">Hongcheng Wang</a>, respectively.
                </p>
                <p>My research interests include:</p>
                <ul style="padding-left: 18px; margin: 0;">
                  <li style="margin-bottom: 10px;">
                    <b>Multi-modal Learning and Vision-Language Model:</b>
                    <a href="https://m2f2-net.github.io/M2F2-Page/"><strong>M2F2-Det</strong></a> (CVPR25-oral),
                    <a href="https://github.com/Reality-Defender/Research-DD-VQA">DDVQA-BLIP</a> (ECCV24),
                    and <a href="https://github.com/SparkleXFantasy/MM-Det">MM-Det</a> (NeurIPS24).
                  </li>
                  <li style="margin-bottom: 10px;">
                    <b>Image Generative Model:</b>
                    <a href="https://chelsea234.github.io/Dense-Face.github.io/"><strong>DenseFace</strong></a> (ArXiv24).
                  </li>
                  <li>
                    <b>Responsible AI</b>, e.g., Deepfake/Anti-spoofing:
                    <a href="https://github.com/CHELSEA234/HiFi_IFDL"><strong>HiFi-Net</strong></a> (CVPR23),
                    <a href="https://link.springer.com/article/10.1007/s11263-024-02255-9">HiFi-Net++</a> (IJCV24),
                    and <a href="https://github.com/CHELSEA234/Multi-domain-learning-FAS">FAS-Wrapper</a> (ECCV22-oral).
                  </li>
                </ul>
                <p style="text-align:center">
                  <a href="mailto:xiao07guo@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/XiaoGuo_cv.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=H93xhggAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/CHELSEA234">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/XiaoGuo.jpg">
                  <img
                    style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;"
                    alt="profile photo"
                    src="images/XiaoGuo.jpg"
                    loading="eager" decoding="async" fetchpriority="high">
                </a>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
          <tbody>
            <h2>News:</h2>
            <div style="max-height: 150px; overflow-y: scroll; padding: 5px; margin-bottom: 30px;">
              <ul style="margin: 0; padding-left: 18px;">
                <li style="font-size: 15px; line-height: 1.5; margin: 2px 0;">2025-06: One co-authored paper is accepted by ICCV25.</li>
                <li style="font-size: 15px; line-height: 1.5; margin: 2px 0;">2025-03: Our <a href="https://m2f2-net.github.io/M2F2-Page/">M2F2-Det</a> is selected as an <span style="color:red; font-weight:bold;">oral presentation</span> (0.7% rate in the total submissions).</li>
                <li style="font-size: 15px; line-height: 1.5; margin: 2px 0;">2025-02: Our <a href="https://m2f2-net.github.io/M2F2-Page/">M2F2-Det</a> is accepted by CVPR25.</li>
                <li style="font-size: 15px; line-height: 1.5; margin: 2px 0;">2024-12: Our <a href="https://chelsea234.github.io/Dense-Face.github.io/">DenseFace</a> is posted on ArXiv.</li>
                <li style="font-size: 15px; line-height: 1.5; margin: 2px 0;">2024-10: Our <a href="https://github.com/CHELSEA234/HiFi_IFDL">HiFi-Net++</a> is accepted by IJCV25.</li>
                <li style="font-size: 15px; line-height: 1.5; margin: 2px 0;">2024-09: Two works (<a href="https://github.com/SparkleXFantasy/MM-Det">MM-Det</a> and <a href="https://github.com/CHELSEA234/LGPN">LGPN</a>) are accepted by NeurIPS24.</li>
                <li style="font-size: 15px; line-height: 1.5; margin: 2px 0;">2024-09: Completed my internship at Amazon One!</li>
                <li style="font-size: 15px; line-height: 1.5; margin: 2px 0;">2023-09: Completed my internship at Amazon Alexa!</li>
              </ul>
            </div>

            <h2>Selected Publications:</h2>
            <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;margin-bottom:30px;">
              <tr><td style="padding:6px"></td></tr>

              <tr bgcolor="#ffffd0">
                <td width="40%" valign="middle" align="left">
                  <div class="one">
                    <img id="m2f2_img" src="images/M2F2_Det.png" alt="M2F2-Det teaser" loading="lazy" decoding="async">
                  </div>
                </td>
                <td width="60%" valign="middle">
                  <table width="100%"><tr><td>
                    <a href="https://m2f2-net.github.io/M2F2-Page/">
                      <span class="papertitle">Rethinking Vision-Language Model in Face Forensics: Multi-Modal Interpretable Forged Face Detector</span>
                    </a>
                    <br>
                    <strong>Xiao Guo</strong>,
                    <a href="https://scholar.google.com/citations?user=qO93EgIAAAAJ&hl=en">Xiufeng Song</a>,
                    <a href="https://www.egr.msu.edu/~zhan1624/">Yue Zhang</a>,
                    <a href="https://jhc.sjtu.edu.cn/~xiaohongliu/">Xiaohong Liu</a>,
                    <a href="https://cvlab.cse.msu.edu/">Xiaoming Liu</a>
                    <br>
                    <em>CVPR (<span style="color:red; font-weight:bold;">Oral Presentation</span>)</em>, 2025
                    <br>
                    <a href="https://m2f2-net.github.io/M2F2-Page/">project page</a>
                    /
                    <a href="https://github.com/CHELSEA234/M2F2_Det/">code<img src="https://img.shields.io/github/stars/CHELSEA234/M2F2_Det?style=social" alt="GitHub stars" height="15"></a>
                    /
                    <a href="https://arxiv.org/pdf/2503.20188">arXiv</a>
                    <p></p>
                    <p>Formulating a deepfake detection task with Large Language Model.</p>
                  </td></tr></table>
                </td>
              </tr>

              <tr bgcolor="#ffffd0">
                <td style="padding-left:0;width:40%;vertical-align:middle;text-align:center;">
                  <div class="one">
                    <img id="denseface_img" src="images/Dense-Face.png" alt="DenseFace teaser" loading="lazy" decoding="async">
                  </div>
                </td>
                <td style="padding:0;width:100%;vertical-align:middle;">
                  <a href="https://chelsea234.github.io/Dense-Face.github.io/">
                    <span class="papertitle">Dense-Face: Personalized Face Generation Model via Dense Annotation Prediction</span>
                  </a>
                  <br>
                  <strong>Xiao Guo</strong>,
                  Manh Tran,
                  <a href="https://scholar.google.com/citations?user=cPeV9YIAAAAJ&hl=en">Jiaxin Cheng</a>,
                  <a href="https://cvlab.cse.msu.edu/">Xiaoming Liu</a>
                  <br>
                  <em>arXiv</em>, 2024
                  <br>
                  <a href="https://chelsea234.github.io/Dense-Face.github.io/">project page</a>
                  /
                  <a href="https://github.com/CHELSEA234/Dense-Face"> code <img src="https://img.shields.io/github/stars/CHELSEA234/Dense-Face?style=social" alt="GitHub stars" height="15"></a>
                  /
                  <a href="https://arxiv.org/pdf/2412.18149">arXiv</a>
                  <p></p>
                  <p>A personalized face generation T2I diffusion model via dense landmarks prediction.</p>
                </td>
              </tr>

              <tr bgcolor="#ffffd0">
                <td style="padding-left:0;width:40%;vertical-align:middle;text-align:center;">
                  <div class="one">
                    <!-- Exact thumbnail behavior restored here -->
                    <img id="hifinet_img_v2" src="images/HiFi_Net.png" alt="HiFi-Net teaser" loading="lazy" decoding="async">
                  </div>
                </td>
                <td style="padding:0;width:100%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2303.17111">
                    <span class="papertitle">Hierarchical FineGrained Image Forgery Detection and Localization</span>
                  </a>
                  <br>
                  <strong>Xiao Guo</strong>,
                  <a href="https://jhc.sjtu.edu.cn/~xiaohongliu/">Xiaohong Liu</a>,
                  <a href="https://zhiyuan-r.github.io/">Zhiyuan Ren</a>,
                  <a href="https://scholar.google.com/citations?user=I1wOjTYUyYAC&hl=en">Steven Grosz</a>,
                  <a href="https://iacopomasi.github.io/">Iacopo Masi</a>,
                  <a href="https://cvlab.cse.msu.edu/">Xiaoming Liu</a>
                  <br>
                  <em>CVPR</em>, 2023
                  <br>
                  <a href="https://github.com/CHELSEA234/HiFi_IFDL">code <img src="https://img.shields.io/github/stars/CHELSEA234/HiFi_IFDL?style=social" alt="GitHub stars" height="15"></a>
                  /
                  <a href="https://arxiv.org/pdf/2303.17111">arXiv</a>
                  <p></p>
                  <p>An image forgery detection and localization method for both digital manipulation and image editing domains.</p>
                </td>
              </tr>

              <tr>
                <td style="padding-left:0;width:40%;vertical-align:middle;text-align:center;">
                  <div class="one">
                    <!-- Exact thumbnail behavior restored here -->
                    <img id="mdfas_image" src="images/MDFAS.gif" alt="MDFAS teaser" loading="lazy" decoding="async">
                  </div>
                </td>
                <td style="padding:0;width:100%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2208.11148">
                    <span class="papertitle">Multi-domain Learning for Updating Face Anti-spoofing Models</span>
                  </a>
                  <br>
                  <strong>Xiao Guo</strong>,
                  <a href="https://yaojieliu.github.io/">Yaojie Liu</a>,
                  <a href="https://www.cse.msu.edu/~jain/">Anil Jain</a>,
                  <a href="https://cvlab.cse.msu.edu/">Xiaoming Liu</a>
                  <br>
                  <em>ECCV (<span style="color:red; font-weight:bold;">Oral Presentation</span>)</em>, 2022
                  <br>
                  <a href="https://github.com/CHELSEA234/Multi-domain-learning-FAS">code<img src="https://img.shields.io/github/stars/CHELSEA234/Multi%2Ddomain%2Dlearning%2DFAS" alt="GitHub stars" height="15"></a>
                  /
                  <a href="https://arxiv.org/pdf/2208.11148">arXiv</a>
                  <p>A new model for multi-domain face anti-spoofing, which addresses the forgetting issue when learning new domain data.</p>
                </td>
              </tr>

              <tr>
                <td style="padding-left:0;width:40%;vertical-align:bottom;text-align:center;">
                  <div class="one">
                    <img id="RE_image" src="images/Relation_extraction.png" alt="Relation extraction teaser" loading="lazy" decoding="async">
                  </div>
                </td>
                <td style="padding:0;width:100%;vertical-align:top">
                  <a href="https://arxiv.org/pdf/2101.00124">
                    <span class="papertitle">Discourse-level Relation Extraction via Graph Pooling</span>
                  </a>
                  <br>
                  <a href="https://ihungalexhsu.github.io/">I-Hung Hsu</a>, <strong>Xiao Guo</strong>,
                  <a href="https://scholar.google.com/citations?user=X-NM0rJIU_AC&hl=en">Prem Natarajan</a>,
                  <a href="https://violetpeng.github.io/">Nanyun Peng</a>
                  <br>
                  <em>AAAI Workshop on Deep Learning on Graphs (<span style="color:red; font-weight:bold;">Best Paper Award</span>)</em>, 2022
                  <br>
                  <a href="https://arxiv.org/pdf/2101.00124">arXiv</a> / <a href="https://deep-learning-graphs.bitbucket.io/dlg-aaai22/publications.html">Workshop Page</a>
                </td>
              </tr>
            </table>

            <h2>Other Publications:</h2>
            <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;margin-bottom:30px;">

              <tr><td style="padding:6px"></td></tr>

              <tr>
                <td style="padding-bottom:1px;width:40%;vertical-align:middle">
                  <div class="one">
                    <img id="mmdet_img" src="images/MM-Det.png" alt="MM-Det teaser" loading="lazy" decoding="async">
                  </div>
                </td>
                <td style="padding:0;width:100%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2410.23623">
                    <span class="papertitle">On Learning Multi-Modal Forgery Representation for Diffusion Generated Video Detection</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.com/citations?user=qO93EgIAAAAJ&hl=en">Xiufeng Song</a>,
                  <strong>Xiao Guo</strong>,
                  <em>others </em>,
                  <a href="https://cvlab.cse.msu.edu/">Xiaoming Liu</a>
                  <a href="https://faculty.sjtu.edu.cn/zhaiguangtao/en/index.htm">Guangtao Zhai</a>,
                  <a href="https://jhc.sjtu.edu.cn/~xiaohongliu/">Xiaohong Liu</a>
                  <br>
                  <em>NeurIPS</em>, 2024
                  <br>
                  <a href="https://github.com/SparkleXFantasy/MM-Det/">code<img src="https://img.shields.io/github/stars/SparkleXFantasy/MM-Det?style=social" alt="GitHub stars" height="15"></a>
                  /
                  <a href="https://arxiv.org/pdf/2410.23623">arXiv</a>
                  <p></p>
                  <p>A forgery video detection method based the LLama-2.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:0;width:40%;vertical-align:middle">
                  <div class="one">
                    <img id="ddvqa_img" src="images/DDVQA-BLIP.gif" alt="DDVQA-BLIP teaser" loading="lazy" decoding="async">
                  </div>
                </td>
                <td style="padding:0;width:100%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2402.00126">
                    <span class="papertitle">Common Sense Reasoning for Deepfake Detection</span>
                  </a>
                  <br>
                  <a href="https://www.egr.msu.edu/~zhan1624/">Yue Zhang</a>,
                  Ben Colman,
                  <strong>Xiao Guo</strong>,
                  Ali Shahriyari,
                  <a href="https://gauravbharaj.github.io/">Gaurav Bharaj</a>
                  <br>
                  <em>ECCV</em>, 2024
                  <br>
                  <a href="https://github.com/Reality-Defender/Research-DD-VQA">code<img src="https://img.shields.io/github/stars/Reality-Defender/Research-DD-VQA?style=social" alt="GitHub stars" height="15"></a>
                  /
                  <a href="https://arxiv.org/pdf/2402.00126">arXiv</a>
                  <p></p>
                  <p>Fine-tuning BLIP for deepfake detection VQA.</p>
                </td>
              </tr>

              <tr>
                <td style="padding-left:0;width:40%;vertical-align:middle;text-align:left;">
                  <div class="one">
                    <img id="hifinet_img" src="images/HiFi_Net.png" alt="HiFi-Net++ teaser" loading="lazy" decoding="async">
                  </div>
                </td>
                <td style="padding:0;width:100%;vertical-align:middle">
                  <a href="https://link.springer.com/article/10.1007/s11263-024-02255-9">
                    <span class="papertitle">Language-guided Hierarchical Finegrained Image Forgery Detection and Localization</span>
                  </a>
                  <br>
                  <strong>Xiao Guo</strong>,
                  <a href="https://jhc.sjtu.edu.cn/~xiaohongliu/">Xiaohong Liu</a>,
                  <a href="https://iacopomasi.github.io/">Iacopo Masi</a>,
                  <a href="https://cvlab.cse.msu.edu/">Xiaoming Liu</a>
                  <br>
                  <em>IJCV</em>, 2024
                  <br>
                  <a href="https://github.com/CHELSEA234/HiFi_IFDL">code<img src="https://img.shields.io/github/stars/CHELSEA234/HiFi_IFDL?style=social" alt="GitHub stars" height="15"></a>
                  /
                  <a href="https://link.springer.com/article/10.1007/s11263-024-02255-9">arXiv</a>
                  <p></p>
                  <p>Image Forgery Detection and Localization; An extension work of HiFi-Net (CVPR23).</p>
                </td>
              </tr>

              <tr>
                <td style="padding-left:0;width:40%;vertical-align:middle;text-align:center;">
                  <div class="one">
                    <img id="lpgn_img" src="images/LPGN.png" alt="LGPN teaser" loading="lazy" decoding="async">
                  </div>
                </td>
                <td style="padding:0;width:100%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2312.02224">
                    <span class="papertitle">Tracing Hyperparameter Dependencies for Model Parsing via Learnable Graph Pooling Network</span>
                  </a>
                  <br>
                  <strong>Xiao Guo</strong>,
                  <a href="https://vishal3477.github.io/">Vishal Asnani</a>,
                  <a href="https://lsjxjtu.github.io/"> Sijia Liu</a>,
                  <a href="https://cvlab.cse.msu.edu/">Xiaoming Liu</a>
                  <br>
                  <em>NeurIPS</em>, 2024
                  <br>
                  <a href="https://arxiv.org/pdf/2312.02224">arXiv</a>
                  <p></p>
                  <p>Introduce a learnable graph pooling network for the model parsing.</p>
                </td>
              </tr>

              <tr>
                <td style="padding-left:0;width:40%;vertical-align:middle;text-align:center;">
                  <div class="one">
                    <img id="motion_prediction_image" src="images/Human_motion.png" alt="Human motion prediction teaser" loading="lazy" decoding="async">
                  </div>
                </td>
                <td style="padding:0;width:100%;vertical-align:top">
                  <a href="https://arxiv.org/abs/1902.07367">
                    <span class="papertitle">Human motion prediction via learning local structure representations and temporal dependencies</span>
                  </a>
                  <br>
                  <strong>Xiao Guo</strong>, <a href="https://sites.google.com/view/jongmoochoi">Jongmoo Choi</a>
                  <br>
                  <em>AAAI</em> 2019
                  <br>
                  <a href="https://github.com/CHELSEA234/SkelNet_motion_prediction">code<img src="https://img.shields.io/github/stars/CHELSEA234/SkelNet_motion_prediction?style=social" alt="GitHub stars" height="15"></a>
                  /
                  <a href="https://arxiv.org/abs/1902.07367">arXiv</a>
                </td>
              </tr>
            </table>

            <h2>Academic Services:</h2>
            <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
              <tr><td style="padding:6px"></td></tr>
              <p>I regularly review papers for the following conferences and journals:</p>
              <ul>
                <li>Conferences: CVPR, ICCV, ECCV, AAAI, NeurIPS, ICLR, etc.</li>
                <li>Journals: T-PAMI, IJCV, TIFS, etc.</li>
              </ul>
            </table>
          </tbody>
        </table>
      </td></tr>
    </tbody></table>
  </body>
</html>
